{
 "cells": [
  {
   "cell_type": "raw",
   "id": "50838f8c",
   "metadata": {},
   "source": [
    "---\n",
    "self-contained: True\n",
    "echo: True\n",
    "title: Lab 4\n",
    "author: Tuukka Jaakkola\n",
    "date: '10/30/2023'\n",
    "output: html\n",
    "theme: darkly\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "27128c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "#Disclosure: These list are made by chat GPT\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\"District of Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "state_abbreviations = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "stock_map = {\"Starbucks\": \"sbux?mod=search_symbol\",\n",
    "            \"Dunkin\": \"\",\n",
    "            \"Peet's\": \"jdep?countrycode=nl&mod=search_symbol\",\n",
    "            \"Tim\": \"qsr?mod=search_symbol\",\n",
    "            \"Panera\": \"\",\n",
    "            \"Caribou\": \"qsr?mod=search_symbol\",\n",
    "            \"Au\":\"yum?mod=search_symbol\",\n",
    "            \"The\": \"jfc?countrycode=ph&mod=search_symbol\",\n",
    "            \"McDonald's\": \"mcd?mod=search_symbol\"}\n",
    "\n",
    "northeast = [\"Connecticut\", \"Maine\", \"Massachusetts\", \"New Hampshire\", \"Rhode Island\", \"Vermont\",\"New Jersey\", \"New York\", \"Pennsylvania\"]\n",
    "midwest = [\"Illinois\", \"Indiana\", \"Michigan\", \"Ohio\", \"Wisconsin\",\"Iowa\", \"Kansas\", \"Minnesota\", \"Missouri\", \"Nebraska\", \"North Dakota\", \"South Dakota\"]\n",
    "south = [\"Delaware\", \"Florida\", \"Georgia\", \"Maryland\", \"North Carolina\",\"South Carolina\", \"Virginia\", \"Washington, D.C.\", \"West Virginia\",\"Alabama\", \"Kentucky\", \"Mississippi\", \"Tennessee\",\"Arkansas\", \"Louisiana\", \"Oklahoma\", \"Texas\"]\n",
    "west = [\"Arizona\", \"Colorado\", \"Idaho\", \"Montana\", \"Nevada\",\"New Mexico\", \"Utah\", \"Wyoming\",\"Alaska\", \"California\", \"Hawaii\", \"Oregon\", \"Washington\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e1c09",
   "metadata": {},
   "source": [
    "I chose to Use lists to map the state abbreviations instead of writing a seperate function for it. I am also feeding these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9f37fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(name):\n",
    "    \"\"\"\n",
    "    Find the stock price for the given restaurant\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    name : str\n",
    "        The first word of the retaurant name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    number for stock price\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dunkin and Panera are private companies so price is hardcoded\n",
    "    if name == \"Dunkin'\":\n",
    "        stock_website = 106.48\n",
    "    elif name == \"Panera\":\n",
    "        stock_website = 314.93\n",
    "    # Peet's and The coffee are in a different format on the same page so they are seperated\n",
    "    # I assume this is to do with the foreign markets\n",
    "    elif name == \"Peet's\" or name == \"The\":\n",
    "        ext = stock_map.get(name)\n",
    "\n",
    "        stock_website = get_website(\"https://www.marketwatch.com/investing/stock/\" + ext)\n",
    "\n",
    "        stock_website = stock_website.find(\"div\", {\"class\":\"intraday__data\"})\n",
    "\n",
    "        stock_website = stock_website.find(\"span\")\n",
    "\n",
    "        stock_website = stock_website.text\n",
    "    else:\n",
    "        ext = stock_map.get(name)\n",
    "\n",
    "        stock_website = get_website(\"https://www.marketwatch.com/investing/stock/\" + ext)\n",
    "\n",
    "        stock_website = stock_website.find(\"div\", {\"class\":\"intraday__data\"})\n",
    "\n",
    "        stock_website = stock_website.find(\"bg-quote\")\n",
    "\n",
    "        stock_website = stock_website.text\n",
    "    \n",
    "    return stock_website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6a0cd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_website(url):\n",
    "    \n",
    "    Headers = {\n",
    "    \"user-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36 Edg/118.0.2088.61\" \n",
    "    }\n",
    "    \n",
    "    restaurant = requests.get(url, headers = Headers, timeout = 25)\n",
    "    restaurant_soup = BeautifulSoup(restaurant.content, \"html.parser\")\n",
    "    return restaurant_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9055fe7",
   "metadata": {},
   "source": [
    "The function below returns the data in a slightly different format that the assignment asked since I had a misunderstanding. As menuism is not working, I am not going to try and change the code to the other format as I can't test it. The code below would have a seperate column for each restaurant count rather than a long list of repeated information.\n",
    "\n",
    "This is also the main function and it does everything for a single restaurant, however, it does not pull state populations as that is more convenient to do just once for the full data as this is more of a table format function. I am also not merging any restaurants in this funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "575d2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_loc(url, states = states, state_abbreviations = state_abbreviations):\n",
    "    \"\"\"\n",
    "    Scrapes the menuisim website for the amount of restaurant locations for the link provided\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    url : str\n",
    "        A url link in quotation marks for the desired restaurant chain\n",
    "    states : lsit\n",
    "        A list of specific states wanted\n",
    "    state_abbreviations : dict\n",
    "        A dictionary mapping states to the desired abbreviations\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe \n",
    "    A pandas dataframe containing states, abbreviations, and counts for the desired chain\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the desired html file\n",
    "    restaurant_soup = get_website(url)\n",
    "    \n",
    "    # Find the list of restaurant locations\n",
    "    restaurant = restaurant_soup.find(\"div\", {\"class\":\"col-sm-6\"})\n",
    "    # Find all instances (locations)\n",
    "    restaurant = restaurant.find_all(\"li\")\n",
    "    \n",
    "    # Initialize an empty list\n",
    "    rows = []\n",
    "\n",
    "    # Iterate over all rows in the retaurant list\n",
    "    for location in restaurant:\n",
    "        \n",
    "        # Creates and empty variable state\n",
    "        state = \"\"\n",
    "\n",
    "        # take each state (already contains the location count)\n",
    "        state_tag = location.find(\"a\")\n",
    "        if state_tag is not None:\n",
    "            state = state_tag.text\n",
    "        else:\n",
    "            None\n",
    "\n",
    "        # Append this data.\n",
    "        rows.append({\n",
    "            \"State\": state\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    data = pd.DataFrame(rows)\n",
    "    \n",
    "    # remove ()\n",
    "    data[\"State\"] = data[\"State\"].apply(lambda x: x.replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "    \n",
    "    # Split the count from the rest of the string\n",
    "    data[[\"State\",\"Count\"]] = data[\"State\"].str.rsplit(pat = \" \",n = 1, expand = True)\n",
    "    \n",
    "    # Check for the states and find the right location to split the state to it's own column\n",
    "    if data[\"State\"].iloc(0) in (\"New\", \"South\", \"West\", \"Rhode\"):\n",
    "        data[[\"State\", \"name\"]] = data[\"State\"].str.split(pat = \" \",n = 2, expand = True)\n",
    "    elif data[\"State\"].iloc(0) == (\"District\"):\n",
    "        data[[\"State\", \"name\"]] = data[\"State\"].str.split(pat = \" \",n = 3, expand = True)\n",
    "    else:\n",
    "        data[[\"State\", \"name\"]] = data[\"State\"].str.split(pat = \" \",n = 1, expand = True)\n",
    "    \n",
    "    # check if the area in state column is in fact a state\n",
    "    data = data[data[\"State\"].isin(states)]\n",
    "    \n",
    "    # take the name of the restaurant (remaining string)\n",
    "    name = data[\"name\"][1]\n",
    "    \n",
    "    # Use the previous string to rename the count column\n",
    "    data.rename(columns={'Count':name}, inplace=True)\n",
    "    \n",
    "    # Drop the extra column\n",
    "    data.drop(\"name\", axis = 1, inplace = True)\n",
    "    \n",
    "    # Add a column with state abbreviations\n",
    "    data[\"ST\"] = data[\"State\"].map(state_abbreviations)\n",
    "    \n",
    "    # Re-organize columns\n",
    "    data = data[[\"State\", \"ST\", name]]\n",
    "    \n",
    "    # Theoretically this will add a column with the right stock price but I can't test as menuism site is not working\n",
    "    data[\"Stock Price\"] = get_price(name.split(\"\", 1)[0])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5405a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_pop(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes a link (wikipedia) and returns the state name and population\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    url : str\n",
    "        A url link in quotation marks for the desired wikipwdia page (state population)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe \n",
    "    A pandas dataframe containing states and population\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    wiki = get_website(url)\n",
    "    wiki.find(\"table\")\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    # iterate over all rows in the faculty table\n",
    "    for state in wiki.find_all(\"tr\")[1:]:\n",
    "         # Get all the cells (<td>) in the row.\n",
    "        cells = state.find_all(\"td\")\n",
    "        \n",
    "        # Find the state of the city in cell[1]\n",
    "        # which for most states is contained in the <i> tag\n",
    "        state_tag = cells[2].find(\"a\") or cells[2]\n",
    "        state = state_tag.text\n",
    "\n",
    "        # which for most populations is contained in the <a> tag\n",
    "        population_tag = cells[3].find(\"td\") or cells[3]\n",
    "        population = population_tag.text\n",
    "        population = population.replace(\"\\n\", \"\")\n",
    "\n",
    "         # Append this data.\n",
    "        rows.append({\n",
    "            \"state\": state,\n",
    "            \"population\": population,\n",
    "    })\n",
    "        \n",
    "    \n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1a5ac133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region(state):\n",
    "    # Simple function returning the region for a state based on a list\n",
    "    if state in northeast:\n",
    "        area = \"Northeast\"\n",
    "    elif state in midwest:\n",
    "        area = \"Midwest\"\n",
    "    elif state in south:\n",
    "        area = \"South\"\n",
    "    elif state in west:\n",
    "        area = \"West\"\n",
    "    else:\n",
    "        area = \"Undefined\"\n",
    "    return area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24695cc7",
   "metadata": {},
   "source": [
    "Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f57ac833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data1 \u001b[38;5;241m=\u001b[39m rest_loc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.menuism.com/restaurant-locations/starbucks-coffee-39564\u001b[39m\u001b[38;5;124m\"\u001b[39m, states, state_abbreviations)\n",
      "Cell \u001b[1;32mIn[138], line 27\u001b[0m, in \u001b[0;36mrest_loc\u001b[1;34m(url, states, state_abbreviations)\u001b[0m\n\u001b[0;32m     25\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant_soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol-sm-6\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Find all instances (locations)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize an empty list\u001b[39;00m\n\u001b[0;32m     30\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "#data1 = rest_loc(\"https://www.menuism.com/restaurant-locations/starbucks-coffee-39564\", states, state_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "903d156d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data2 = rest_loc(\"https://www.menuism.com/restaurant-locations/dunkin-donuts-181624\", states, state_abbreviations)\n",
    "\n",
    "#data1 = data1.merge(data2, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ad368b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data3 = rest_loc(\"https://www.menuism.com/restaurant-locations/peets-coffee-tea-84051\", states, state_abbreviations)\n",
    "\n",
    "#data1 = data1.merge(data3, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9cb8b50e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data4 = rest_loc(\"https://www.menuism.com/restaurant-locations/tim-hortons-190025\", states, state_abbreviations)\n",
    "\n",
    "#data1 = data1.merge(data4, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "346e1d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data5 = rest_loc(\"https://www.menuism.com/restaurant-locations/panera-bread-4258\", states, state_abbreviations)\n",
    "\n",
    "#data1 = data1.merge(data5, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "78fbe866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[239], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data6 \u001b[38;5;241m=\u001b[39m rest_loc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.menuism.com/restaurant-locations/caribou-coffee-164861\u001b[39m\u001b[38;5;124m\"\u001b[39m, states, state_abbreviations)\n\u001b[0;32m      3\u001b[0m data1 \u001b[38;5;241m=\u001b[39m data1\u001b[38;5;241m.\u001b[39mmerge(data6, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST\u001b[39m\u001b[38;5;124m\"\u001b[39m], how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[238], line 27\u001b[0m, in \u001b[0;36mrest_loc\u001b[1;34m(url, states, state_abbreviations)\u001b[0m\n\u001b[0;32m     25\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant_soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol-sm-6\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Find all instances (locations)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize an empty list\u001b[39;00m\n\u001b[0;32m     30\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "#data6 = rest_loc(\"https://www.menuism.com/restaurant-locations/caribou-coffee-164861\", states, state_abbreviations)\n",
    "\n",
    "#data1 = data1.merge(data6, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81a7cab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data7 = rest_loc(\"https://www.menuism.com/restaurant-locations/au-bon-pain-69342\", states, state_abbreviations)\n",
    "\n",
    "#data1 = data1.merge(data7, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bc57e2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data8 = rest_loc(\"https://www.menuism.com/restaurant-locations/the-coffee-bean-tea-leaf-165988\", states, state_abbreviations)\n",
    "\n",
    "#data1 = data1.merge(data8, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "75c560d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data9 \u001b[38;5;241m=\u001b[39m rest_loc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.menuism.com/restaurant-locations/mcdonalds-21019\u001b[39m\u001b[38;5;124m\"\u001b[39m, states, state_abbreviations)\n\u001b[0;32m      3\u001b[0m data1 \u001b[38;5;241m=\u001b[39m data1\u001b[38;5;241m.\u001b[39mmerge(data9, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST\u001b[39m\u001b[38;5;124m\"\u001b[39m], how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m data_temp \u001b[38;5;241m=\u001b[39m data1\n",
      "Cell \u001b[1;32mIn[138], line 27\u001b[0m, in \u001b[0;36mrest_loc\u001b[1;34m(url, states, state_abbreviations)\u001b[0m\n\u001b[0;32m     25\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant_soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol-sm-6\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Find all instances (locations)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize an empty list\u001b[39;00m\n\u001b[0;32m     30\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "#data9 = rest_loc(\"https://www.menuism.com/restaurant-locations/mcdonalds-21019\", states, state_abbreviations)\n",
    "\n",
    "#data1 = data1.merge(data9, on=[\"State\", \"ST\"], how = 'left')\n",
    "\n",
    "#data_temp = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0f697227",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[256], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m pop \u001b[38;5;241m=\u001b[39m state_pop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://simple.wikipedia.org/wiki/List_of_U.S._states_by_population\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Merge the data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m data_pop \u001b[38;5;241m=\u001b[39m data_temp\u001b[38;5;241m.\u001b[39mmerge(pop, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Move the pop column to after the abbreviation\u001b[39;00m\n\u001b[0;32m      9\u001b[0m col \u001b[38;5;241m=\u001b[39m data_pop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopulation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_temp' is not defined"
     ]
    }
   ],
   "source": [
    "# Use the function to scrape the wikipedia page\n",
    "pop = state_pop(\"https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population\")\n",
    "\n",
    "# Merge the data\n",
    "data_pop = data_temp.merge(pop, how='left', left_on='State', right_on='state')\n",
    "\n",
    "# Move the pop column to after the abbreviation\n",
    "\n",
    "col = data_pop[\"population\"]\n",
    "data_pop.drop(columns=[\"population\"], inplace=True)\n",
    "data_pop.insert(2, col.name,col)\n",
    "\n",
    "# Creating a region column\n",
    "data_pop[\"Region\"] = data_pop[\"State\"].apply(lambda x: get_region(x))\n",
    "\n",
    "col = data_pop[\"Region\"]\n",
    "data_pop.drop(columns=[\"Region\"], inplace=True)\n",
    "data_pop.insert(3, col.name,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa8ba0",
   "metadata": {},
   "source": [
    "This is using the shared data as instructed due to the website not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "26972d28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             State  ST     Region Coffee Chain  Location Count  Population  \\\n",
      "0           Alaska  AK       West    Starbucks              24      733391   \n",
      "1          Alabama  AL      South    Starbucks              73     5024279   \n",
      "2         Arkansas  AR      South    Starbucks              33     3011524   \n",
      "3          Arizona  AZ       West    Starbucks             279     7151502   \n",
      "4       California  CA       West    Starbucks            2362    39538223   \n",
      "..             ...  ..        ...          ...             ...         ...   \n",
      "264        Vermont  VT  Northeast   McDonald's              30      643077   \n",
      "265     Washington  WA       West   McDonald's             326     7705281   \n",
      "266      Wisconsin  WI    Midwest   McDonald's             353     5893718   \n",
      "267  West Virginia  WV      South   McDonald's             107     1793716   \n",
      "268        Wyoming  WY       West   McDonald's              34      576851   \n",
      "\n",
      "    Stock Price  \n",
      "0         91.99  \n",
      "1         91.99  \n",
      "2         91.99  \n",
      "3         91.99  \n",
      "4         91.99  \n",
      "..          ...  \n",
      "264      256.47  \n",
      "265      256.47  \n",
      "266      256.47  \n",
      "267      256.47  \n",
      "268      256.47  \n",
      "\n",
      "[269 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "imported = pd.read_csv(r\"C:\\Users\\tuke-\\Desktop\\1_GSB544_Computing_and_Machine_Learning\\Week_4\\LAB4\\df_lab4_scraped.csv\")\n",
    "\n",
    "# Creating a region column\n",
    "imported[\"Region\"] = imported[\"State\"].apply(lambda x: get_region(x))\n",
    "\n",
    "stock_price = {\"Starbucks\":get_price(\"Starbucks\"),\n",
    "                \"Dunkin' Donuts\":get_price(\"Dunkin'\"),\n",
    "                \"Peet's Coffee & Tea\":get_price(\"Peet's\"),\n",
    "                \"Tim Horton's\":get_price(\"Tim\"),\n",
    "                \"Panera Bread\":get_price(\"Panera\"),\n",
    "                \"Caribou Coffee\":get_price(\"Caribou\"),\n",
    "                \"Au Bon Pain\":get_price(\"Au\"),\n",
    "                \"The Coffee Bean & Tea Leaf\":get_price(\"The\"),\n",
    "                \"McDonald's\":get_price(\"McDonald's\"),\n",
    "                \n",
    "    \n",
    "}\n",
    "\n",
    "imported[\"Stock Price\"] = imported[\"Coffee Chain\"].map(stock_price)\n",
    "\n",
    "data_pop = imported\n",
    "\n",
    "col = data_pop[\"Region\"]\n",
    "data_pop.drop(columns=[\"Region\"], inplace=True)\n",
    "data_pop.insert(3, col.name,col)\n",
    "\n",
    "col = data_pop[\"Coffee Chain\"]\n",
    "data_pop.drop(columns=[\"Coffee Chain\"], inplace=True)\n",
    "data_pop.insert(3, col.name,col)\n",
    "\n",
    "\n",
    "print(data_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c8024f",
   "metadata": {},
   "source": [
    "7. \n",
    "\n",
    "It is interesting how many Starbucks stores there are in California compared to some other states, it does not seem to scale with population. It is also interesting to see that especially the Canadian chains have mostly remained in Canada or close to it which makes sense, however, you might think if they are crossing the border they would try to spread as wide as possible. The financial data in terms of stock price cannot really be used to draw comparrisons directly as it does not actually tell us anything about the relative performance of the companies. It may be useful for comparing a single companys performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25d805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
