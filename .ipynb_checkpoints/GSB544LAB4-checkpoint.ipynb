{
 "cells": [
  {
   "cell_type": "raw",
   "id": "50838f8c",
   "metadata": {},
   "source": [
    "---\n",
    "self-contained: True\n",
    "title: Lab 4\n",
    "author: Tuukka Jaakkola\n",
    "date: '10/30/2023'\n",
    "output: html\n",
    "theme: darkly\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "27128c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "#Disclosure: These list are made by chat GPT\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\"District of Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "state_abbreviations = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "stock_map = {\"Starbucks\": \"sbux?mod=search_symbol\",\n",
    "            \"Dunkin\": \"\",\n",
    "            \"Peet's\": \"jdep?countrycode=nl&mod=search_symbol\",\n",
    "            \"Tim\": \"qsr?mod=search_symbol\",\n",
    "            \"Panera\": \"\",\n",
    "            \"Caribou\": \"qsr?mod=search_symbol\",\n",
    "            \"Au\":\"yum?mod=search_symbol\",\n",
    "            \"The\": \"jfc?countrycode=ph&mod=search_symbol\",\n",
    "            \"McDonald's\": \"mcd?mod=search_symbol\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f2e1a",
   "metadata": {},
   "source": [
    "I chose to Use lists to map the state abbreviations instead of writing a seperate function for it. I am also feeding these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "963305fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(name):\n",
    "    \"\"\"\n",
    "    Find the stock price for the given restaurant\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    name : str\n",
    "        The first word of the retaurant name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    number for stock price\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dunkin and Panera are private companies so price is hardcoded\n",
    "    if name == \"Dunkin\":\n",
    "        stock_website = 106.48\n",
    "    elif name == \"Panera\":\n",
    "        stock_website = 314.93\n",
    "    # Peet's and The coffee are in a different format on the same page so they are seperated\n",
    "    # I assume this is to do with the foreign markets\n",
    "    elif name == \"Peet's\" or name == \"The\":\n",
    "        ext = stock_map.get(name)\n",
    "\n",
    "        stock_website = get_website(\"https://www.marketwatch.com/investing/stock/\" + ext)\n",
    "\n",
    "        stock_website = stock_website.find(\"div\", {\"class\":\"intraday__data\"})\n",
    "\n",
    "        stock_website = stock_website.find(\"span\")\n",
    "\n",
    "        stock_website = stock_website.text\n",
    "    else:\n",
    "        ext = stock_map.get(name)\n",
    "\n",
    "        stock_website = get_website(\"https://www.marketwatch.com/investing/stock/\" + ext)\n",
    "\n",
    "        stock_website = stock_website.find(\"div\", {\"class\":\"intraday__data\"})\n",
    "\n",
    "        stock_website = stock_website.find(\"bg-quote\")\n",
    "\n",
    "        stock_website = stock_website.text\n",
    "    \n",
    "    print(stock_website)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a651ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_website(url):\n",
    "    \n",
    "    Headers = {\n",
    "    \"user-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36 Edg/118.0.2088.61\" \n",
    "    }\n",
    "    \n",
    "    restaurant = requests.get(url, headers = Headers, timeout = 25)\n",
    "    restaurant_soup = BeautifulSoup(restaurant.content, \"html.parser\")\n",
    "    return restaurant_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "fea4f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_loc(url, states = states, state_abbreviations = state_abbreviations):\n",
    "    \"\"\"\n",
    "    Scrapes the menuisim website for the amount of restaurant locations for the link provided\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    url : str\n",
    "        A url link in quotation marks for the desired restaurant chain\n",
    "    states : lsit\n",
    "        A list of specific states wanted\n",
    "    state_abbreviations : dict\n",
    "        A dictionary mapping states to the desired abbreviations\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe \n",
    "    A pandas dataframe containing states, abbreviations, and counts for the desired chain\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the desired html file\n",
    "    restaurant_soup = get_website(url)\n",
    "    \n",
    "    # Find the list of restaurant locations\n",
    "    restaurant = restaurant_soup.find(\"div\", {\"class\":\"col-sm-6\"})\n",
    "    # Find all instances (locations)\n",
    "    restaurant = restaurant.find_all(\"li\")\n",
    "    \n",
    "    # Initialize an empty list\n",
    "    rows = []\n",
    "\n",
    "    # Iterate over all rows in the retaurant list\n",
    "    for location in restaurant:\n",
    "        \n",
    "        # Creates and empty variable state\n",
    "        state = \"\"\n",
    "\n",
    "        # take each state (already contains the location count)\n",
    "        state_tag = location.find(\"a\")\n",
    "        if state_tag is not None:\n",
    "            state = state_tag.text\n",
    "        else:\n",
    "            None\n",
    "\n",
    "        # Append this data.\n",
    "        rows.append({\n",
    "            \"State\": state\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    data = pd.DataFrame(rows)\n",
    "    \n",
    "    # remove ()\n",
    "    data[\"State\"] = data[\"State\"].apply(lambda x: x.replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "    \n",
    "    # Split the count from the rest of the string\n",
    "    data[[\"State\",\"Count\"]] = data[\"State\"].str.rsplit(pat = \" \",n = 1, expand = True)\n",
    "    \n",
    "    # Check for the states and find the right location to split the state to it's own column\n",
    "    if data[\"State\"].iloc(0) in (\"New\", \"South\", \"West\", \"Rhode\"):\n",
    "        data[[\"State\", \"name\"]] = data[\"State\"].str.split(pat = \" \",n = 2, expand = True)\n",
    "    elif data[\"State\"].iloc(0) == (\"District\"):\n",
    "        data[[\"State\", \"name\"]] = data[\"State\"].str.split(pat = \" \",n = 3, expand = True)\n",
    "    else:\n",
    "        data[[\"State\", \"name\"]] = data[\"State\"].str.split(pat = \" \",n = 1, expand = True)\n",
    "    \n",
    "    # check if the area in state column is in fact a state\n",
    "    data = data[data[\"State\"].isin(states)]\n",
    "    \n",
    "    # take the name of the restaurant (remaining string)\n",
    "    name = data[\"name\"][1]\n",
    "    \n",
    "    # Use the previous string to rename the count column\n",
    "    data.rename(columns={'Count':name}, inplace=True)\n",
    "    \n",
    "    # Drop the extra column\n",
    "    data.drop(\"name\", axis = 1, inplace = True)\n",
    "    \n",
    "    # Add a column with state abbreviations\n",
    "    data[\"ST\"] = data[\"State\"].map(state_abbreviations)\n",
    "    \n",
    "    # Re-organize columns\n",
    "    data = data[[\"State\", \"ST\", name]]\n",
    "    \n",
    "    data[\"Stock Price\"] = get_price(name.split(\"\", 1)[0])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9abd2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_pop(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes a link (wikipedia) and returns the state name and population\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    url : str\n",
    "        A url link in quotation marks for the desired wikipwdia page (state population)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe \n",
    "    A pandas dataframe containing states and population\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    wiki = get_website(url)\n",
    "    wiki.find(\"table\")\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    # iterate over all rows in the faculty table\n",
    "    for state in wiki.find_all(\"tr\")[1:]:\n",
    "         # Get all the cells (<td>) in the row.\n",
    "        cells = state.find_all(\"td\")\n",
    "        \n",
    "        # Find the state of the city in cell[1]\n",
    "        # which for most states is contained in the <i> tag\n",
    "        state_tag = cells[2].find(\"a\") or cells[2]\n",
    "        state = state_tag.text\n",
    "\n",
    "        # which for most populations is contained in the <a> tag\n",
    "        population_tag = cells[3].find(\"td\") or cells[3]\n",
    "        population = population_tag.text\n",
    "        population = population.replace(\"\\n\", \"\")\n",
    "\n",
    "         # Append this data.\n",
    "        rows.append({\n",
    "            \"state\": state,\n",
    "            \"population\": population,\n",
    "    })\n",
    "        \n",
    "    \n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f57ac833",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data1 \u001b[38;5;241m=\u001b[39m rest_loc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.menuism.com/restaurant-locations/starbucks-coffee-39564\u001b[39m\u001b[38;5;124m\"\u001b[39m, states, state_abbreviations)\n",
      "Cell \u001b[1;32mIn[138], line 27\u001b[0m, in \u001b[0;36mrest_loc\u001b[1;34m(url, states, state_abbreviations)\u001b[0m\n\u001b[0;32m     25\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant_soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol-sm-6\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Find all instances (locations)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize an empty list\u001b[39;00m\n\u001b[0;32m     30\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "data1 = rest_loc(\"https://www.menuism.com/restaurant-locations/starbucks-coffee-39564\", states, state_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "903d156d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data2 = rest_loc(\"https://www.menuism.com/restaurant-locations/dunkin-donuts-181624\", states, state_abbreviations)\n",
    "\n",
    "data1 = data1.merge(data2, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ad368b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data3 = rest_loc(\"https://www.menuism.com/restaurant-locations/peets-coffee-tea-84051\", states, state_abbreviations)\n",
    "\n",
    "data1 = data1.merge(data3, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9cb8b50e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data4 = rest_loc(\"https://www.menuism.com/restaurant-locations/tim-hortons-190025\", states, state_abbreviations)\n",
    "\n",
    "data1 = data1.merge(data4, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "346e1d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data5 = rest_loc(\"https://www.menuism.com/restaurant-locations/panera-bread-4258\", states, state_abbreviations)\n",
    "\n",
    "data1 = data1.merge(data5, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "78fbe866",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data6 \u001b[38;5;241m=\u001b[39m rest_loc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.menuism.com/restaurant-locations/caribou-coffee-164861\u001b[39m\u001b[38;5;124m\"\u001b[39m, states, state_abbreviations)\n\u001b[0;32m      3\u001b[0m data1 \u001b[38;5;241m=\u001b[39m data1\u001b[38;5;241m.\u001b[39mmerge(data6, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST\u001b[39m\u001b[38;5;124m\"\u001b[39m], how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[89], line 8\u001b[0m, in \u001b[0;36mrest_loc\u001b[1;34m(url, states, state_abbreviations)\u001b[0m\n\u001b[0;32m      4\u001b[0m restaurant_soup \u001b[38;5;241m=\u001b[39m get_website(url)\n\u001b[0;32m      6\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant_soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol-sm-6\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m----> 8\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize an empty list\u001b[39;00m\n\u001b[0;32m     11\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "data6 = rest_loc(\"https://www.menuism.com/restaurant-locations/caribou-coffee-164861\", states, state_abbreviations)\n",
    "\n",
    "data1 = data1.merge(data6, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81a7cab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data7 = rest_loc(\"https://www.menuism.com/restaurant-locations/au-bon-pain-69342\", states, state_abbreviations)\n",
    "\n",
    "data1 = data1.merge(data7, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bc57e2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data8 = rest_loc(\"https://www.menuism.com/restaurant-locations/the-coffee-bean-tea-leaf-165988\", states, state_abbreviations)\n",
    "\n",
    "data1 = data1.merge(data8, on=[\"State\", \"ST\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "75c560d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data9 \u001b[38;5;241m=\u001b[39m rest_loc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.menuism.com/restaurant-locations/mcdonalds-21019\u001b[39m\u001b[38;5;124m\"\u001b[39m, states, state_abbreviations)\n\u001b[0;32m      3\u001b[0m data1 \u001b[38;5;241m=\u001b[39m data1\u001b[38;5;241m.\u001b[39mmerge(data9, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST\u001b[39m\u001b[38;5;124m\"\u001b[39m], how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m data_temp \u001b[38;5;241m=\u001b[39m data1\n",
      "Cell \u001b[1;32mIn[138], line 27\u001b[0m, in \u001b[0;36mrest_loc\u001b[1;34m(url, states, state_abbreviations)\u001b[0m\n\u001b[0;32m     25\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant_soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol-sm-6\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Find all instances (locations)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m restaurant \u001b[38;5;241m=\u001b[39m restaurant\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Initialize an empty list\u001b[39;00m\n\u001b[0;32m     30\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "data9 = rest_loc(\"https://www.menuism.com/restaurant-locations/mcdonalds-21019\", states, state_abbreviations)\n",
    "\n",
    "data1 = data1.merge(data9, on=[\"State\", \"ST\"], how = 'left')\n",
    "\n",
    "data_temp = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0f697227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to scrape the wikipedia page\n",
    "pop = state_pop(\"https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population\")\n",
    "\n",
    "# Merge the data\n",
    "data_pop = data_temp.merge(pop, how='left', left_on='State', right_on='state')\n",
    "\n",
    "# Move the pop column to after the abbreviation\n",
    "\n",
    "col = data_pop[\"population\"]\n",
    "data_pop.drop(columns=[\"population\"], inplace=True)\n",
    "data_pop.insert(2, col.name,col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "515db94f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            State population_x  population  ST Starbucks Coffee locations  \\\n",
      "0          Alaska      733,391     733,391  AK                         24   \n",
      "1         Alabama    5,024,279   5,024,279  AL                         73   \n",
      "2        Arkansas    3,011,524   3,011,524  AR                         33   \n",
      "3         Arizona    7,151,502   7,151,502  AZ                        279   \n",
      "4      California   39,538,223  39,538,223  CA                       2362   \n",
      "5        Colorado    5,773,714   5,773,714  CO                        371   \n",
      "6     Connecticut    3,605,944   3,605,944  CT                        107   \n",
      "7        Delaware      989,948     989,948  DE                         20   \n",
      "8         Florida   21,538,187  21,538,187  FL                        616   \n",
      "9         Georgia   10,711,908  10,711,908  GA                        248   \n",
      "10         Hawaii    1,455,271   1,455,271  HI                         72   \n",
      "11           Iowa    3,190,369   3,190,369  IA                         49   \n",
      "12          Idaho    1,839,106   1,839,106  ID                         57   \n",
      "13       Illinois   12,812,508  12,812,508  IL                        455   \n",
      "14        Indiana    6,785,528   6,785,528  IN                        193   \n",
      "15         Kansas    2,937,880   2,937,880  KS                         65   \n",
      "16       Kentucky    4,505,836   4,505,836  KY                         69   \n",
      "17      Louisiana    4,657,757   4,657,757  LA                         76   \n",
      "18  Massachusetts    7,029,917   7,029,917  MA                        208   \n",
      "19       Maryland    6,177,224   6,177,224  MD                        212   \n",
      "20          Maine    1,362,359   1,362,359  ME                         22   \n",
      "21       Michigan   10,077,331  10,077,331  MI                        196   \n",
      "22      Minnesota    5,706,494   5,706,494  MN                        140   \n",
      "23       Missouri    6,154,913   6,154,913  MO                        118   \n",
      "24    Mississippi    2,961,279   2,961,279  MS                         23   \n",
      "25        Montana    1,084,225   1,084,225  MT                         17   \n",
      "26       Nebraska    1,961,504   1,961,504  NE                         30   \n",
      "27         Nevada    3,104,614   3,104,614  NV                        188   \n",
      "28           Ohio   11,799,448  11,799,448  OH                        266   \n",
      "29       Oklahoma    3,959,353   3,959,353  OK                         62   \n",
      "30         Oregon    4,237,256   4,237,256  OR                        279   \n",
      "31   Pennsylvania   13,002,700  13,002,700  PA                        279   \n",
      "32      Tennessee    6,910,840   6,910,840  TN                        126   \n",
      "33          Texas   29,145,505  29,145,505  TX                        720   \n",
      "34           Utah    3,271,616   3,271,616  UT                         59   \n",
      "35       Virginia    8,631,393   8,631,393  VA                        300   \n",
      "36        Vermont      643,077     643,077  VT                          6   \n",
      "37     Washington    7,705,281   7,705,281  WA                        634   \n",
      "38      Wisconsin    5,893,718   5,893,718  WI                        119   \n",
      "39        Wyoming      576,851     576,851  WY                         16   \n",
      "\n",
      "   Dunkin' Donuts locations Peet's Coffee & Tea locations  \\\n",
      "0                       NaN                           NaN   \n",
      "1                         1                           NaN   \n",
      "2                        11                           NaN   \n",
      "3                        74                           NaN   \n",
      "4                        46                           163   \n",
      "5                         5                             3   \n",
      "6                       406                           NaN   \n",
      "7                        57                           NaN   \n",
      "8                       654                           NaN   \n",
      "9                       147                           NaN   \n",
      "10                        1                             1   \n",
      "11                       14                           NaN   \n",
      "12                      NaN                           NaN   \n",
      "13                      579                             3   \n",
      "14                       51                           NaN   \n",
      "15                       12                           NaN   \n",
      "16                       34                           NaN   \n",
      "17                        5                           NaN   \n",
      "18                     1101                           NaN   \n",
      "19                      201                           NaN   \n",
      "20                      102                           NaN   \n",
      "21                       91                           NaN   \n",
      "22                        6                           NaN   \n",
      "23                       21                           NaN   \n",
      "24                        3                           NaN   \n",
      "25                      NaN                           NaN   \n",
      "26                        9                           NaN   \n",
      "27                       26                             1   \n",
      "28                      116                           NaN   \n",
      "29                        6                           NaN   \n",
      "30                        1                             8   \n",
      "31                      402                             1   \n",
      "32                       55                           NaN   \n",
      "33                       93                             3   \n",
      "34                        7                           NaN   \n",
      "35                      147                           NaN   \n",
      "36                       34                           NaN   \n",
      "37                        2                            14   \n",
      "38                       30                           NaN   \n",
      "39                      NaN                           NaN   \n",
      "\n",
      "   Tim Hortons locations Panera Bread locations        state_x  ...  \\\n",
      "0                    NaN                    NaN         Alaska  ...   \n",
      "1                    NaN                     20        Alabama  ...   \n",
      "2                    NaN                     13       Arkansas  ...   \n",
      "3                    NaN                     29        Arizona  ...   \n",
      "4                    NaN                    216     California  ...   \n",
      "5                    NaN                     32       Colorado  ...   \n",
      "6                     10                     41    Connecticut  ...   \n",
      "7                      1                      9       Delaware  ...   \n",
      "8                    NaN                    227        Florida  ...   \n",
      "9                    NaN                     71        Georgia  ...   \n",
      "10                   NaN                    NaN         Hawaii  ...   \n",
      "11                   NaN                     27           Iowa  ...   \n",
      "12                   NaN                      7          Idaho  ...   \n",
      "13                   NaN                    154       Illinois  ...   \n",
      "14                     5                     53        Indiana  ...   \n",
      "15                   NaN                     27         Kansas  ...   \n",
      "16                     3                     30       Kentucky  ...   \n",
      "17                   NaN                      1      Louisiana  ...   \n",
      "18                     5                     77  Massachusetts  ...   \n",
      "19                   NaN                     69       Maryland  ...   \n",
      "20                    27                      5          Maine  ...   \n",
      "21                   191                    108       Michigan  ...   \n",
      "22                     7                     52      Minnesota  ...   \n",
      "23                     1                     91       Missouri  ...   \n",
      "24                   NaN                      4    Mississippi  ...   \n",
      "25                   NaN                    NaN        Montana  ...   \n",
      "26                   NaN                     15       Nebraska  ...   \n",
      "27                   NaN                      6         Nevada  ...   \n",
      "28                   105                    170           Ohio  ...   \n",
      "29                   NaN                     28       Oklahoma  ...   \n",
      "30                   NaN                     12         Oregon  ...   \n",
      "31                     9                    112   Pennsylvania  ...   \n",
      "32                   NaN                     42      Tennessee  ...   \n",
      "33                   NaN                    110          Texas  ...   \n",
      "34                   NaN                    NaN           Utah  ...   \n",
      "35                     1                     98       Virginia  ...   \n",
      "36                   NaN                      6        Vermont  ...   \n",
      "37                   NaN                     16     Washington  ...   \n",
      "38                   NaN                     47      Wisconsin  ...   \n",
      "39                   NaN                    NaN        Wyoming  ...   \n",
      "\n",
      "          state_y population_y        state_x population_x        state_y  \\\n",
      "0          Alaska      733,391         Alaska      733,391         Alaska   \n",
      "1         Alabama    5,024,279        Alabama    5,024,279        Alabama   \n",
      "2        Arkansas    3,011,524       Arkansas    3,011,524       Arkansas   \n",
      "3         Arizona    7,151,502        Arizona    7,151,502        Arizona   \n",
      "4      California   39,538,223     California   39,538,223     California   \n",
      "5        Colorado    5,773,714       Colorado    5,773,714       Colorado   \n",
      "6     Connecticut    3,605,944    Connecticut    3,605,944    Connecticut   \n",
      "7        Delaware      989,948       Delaware      989,948       Delaware   \n",
      "8         Florida   21,538,187        Florida   21,538,187        Florida   \n",
      "9         Georgia   10,711,908        Georgia   10,711,908        Georgia   \n",
      "10         Hawaii    1,455,271         Hawaii    1,455,271         Hawaii   \n",
      "11           Iowa    3,190,369           Iowa    3,190,369           Iowa   \n",
      "12          Idaho    1,839,106          Idaho    1,839,106          Idaho   \n",
      "13       Illinois   12,812,508       Illinois   12,812,508       Illinois   \n",
      "14        Indiana    6,785,528        Indiana    6,785,528        Indiana   \n",
      "15         Kansas    2,937,880         Kansas    2,937,880         Kansas   \n",
      "16       Kentucky    4,505,836       Kentucky    4,505,836       Kentucky   \n",
      "17      Louisiana    4,657,757      Louisiana    4,657,757      Louisiana   \n",
      "18  Massachusetts    7,029,917  Massachusetts    7,029,917  Massachusetts   \n",
      "19       Maryland    6,177,224       Maryland    6,177,224       Maryland   \n",
      "20          Maine    1,362,359          Maine    1,362,359          Maine   \n",
      "21       Michigan   10,077,331       Michigan   10,077,331       Michigan   \n",
      "22      Minnesota    5,706,494      Minnesota    5,706,494      Minnesota   \n",
      "23       Missouri    6,154,913       Missouri    6,154,913       Missouri   \n",
      "24    Mississippi    2,961,279    Mississippi    2,961,279    Mississippi   \n",
      "25        Montana    1,084,225        Montana    1,084,225        Montana   \n",
      "26       Nebraska    1,961,504       Nebraska    1,961,504       Nebraska   \n",
      "27         Nevada    3,104,614         Nevada    3,104,614         Nevada   \n",
      "28           Ohio   11,799,448           Ohio   11,799,448           Ohio   \n",
      "29       Oklahoma    3,959,353       Oklahoma    3,959,353       Oklahoma   \n",
      "30         Oregon    4,237,256         Oregon    4,237,256         Oregon   \n",
      "31   Pennsylvania   13,002,700   Pennsylvania   13,002,700   Pennsylvania   \n",
      "32      Tennessee    6,910,840      Tennessee    6,910,840      Tennessee   \n",
      "33          Texas   29,145,505          Texas   29,145,505          Texas   \n",
      "34           Utah    3,271,616           Utah    3,271,616           Utah   \n",
      "35       Virginia    8,631,393       Virginia    8,631,393       Virginia   \n",
      "36        Vermont      643,077        Vermont      643,077        Vermont   \n",
      "37     Washington    7,705,281     Washington    7,705,281     Washington   \n",
      "38      Wisconsin    5,893,718      Wisconsin    5,893,718      Wisconsin   \n",
      "39        Wyoming      576,851        Wyoming      576,851        Wyoming   \n",
      "\n",
      "   population_y        state_x        state_y population_y          state  \n",
      "0       733,391         Alaska         Alaska      733,391         Alaska  \n",
      "1     5,024,279        Alabama        Alabama    5,024,279        Alabama  \n",
      "2     3,011,524       Arkansas       Arkansas    3,011,524       Arkansas  \n",
      "3     7,151,502        Arizona        Arizona    7,151,502        Arizona  \n",
      "4    39,538,223     California     California   39,538,223     California  \n",
      "5     5,773,714       Colorado       Colorado    5,773,714       Colorado  \n",
      "6     3,605,944    Connecticut    Connecticut    3,605,944    Connecticut  \n",
      "7       989,948       Delaware       Delaware      989,948       Delaware  \n",
      "8    21,538,187        Florida        Florida   21,538,187        Florida  \n",
      "9    10,711,908        Georgia        Georgia   10,711,908        Georgia  \n",
      "10    1,455,271         Hawaii         Hawaii    1,455,271         Hawaii  \n",
      "11    3,190,369           Iowa           Iowa    3,190,369           Iowa  \n",
      "12    1,839,106          Idaho          Idaho    1,839,106          Idaho  \n",
      "13   12,812,508       Illinois       Illinois   12,812,508       Illinois  \n",
      "14    6,785,528        Indiana        Indiana    6,785,528        Indiana  \n",
      "15    2,937,880         Kansas         Kansas    2,937,880         Kansas  \n",
      "16    4,505,836       Kentucky       Kentucky    4,505,836       Kentucky  \n",
      "17    4,657,757      Louisiana      Louisiana    4,657,757      Louisiana  \n",
      "18    7,029,917  Massachusetts  Massachusetts    7,029,917  Massachusetts  \n",
      "19    6,177,224       Maryland       Maryland    6,177,224       Maryland  \n",
      "20    1,362,359          Maine          Maine    1,362,359          Maine  \n",
      "21   10,077,331       Michigan       Michigan   10,077,331       Michigan  \n",
      "22    5,706,494      Minnesota      Minnesota    5,706,494      Minnesota  \n",
      "23    6,154,913       Missouri       Missouri    6,154,913       Missouri  \n",
      "24    2,961,279    Mississippi    Mississippi    2,961,279    Mississippi  \n",
      "25    1,084,225        Montana        Montana    1,084,225        Montana  \n",
      "26    1,961,504       Nebraska       Nebraska    1,961,504       Nebraska  \n",
      "27    3,104,614         Nevada         Nevada    3,104,614         Nevada  \n",
      "28   11,799,448           Ohio           Ohio   11,799,448           Ohio  \n",
      "29    3,959,353       Oklahoma       Oklahoma    3,959,353       Oklahoma  \n",
      "30    4,237,256         Oregon         Oregon    4,237,256         Oregon  \n",
      "31   13,002,700   Pennsylvania   Pennsylvania   13,002,700   Pennsylvania  \n",
      "32    6,910,840      Tennessee      Tennessee    6,910,840      Tennessee  \n",
      "33   29,145,505          Texas          Texas   29,145,505          Texas  \n",
      "34    3,271,616           Utah           Utah    3,271,616           Utah  \n",
      "35    8,631,393       Virginia       Virginia    8,631,393       Virginia  \n",
      "36      643,077        Vermont        Vermont      643,077        Vermont  \n",
      "37    7,705,281     Washington     Washington    7,705,281     Washington  \n",
      "38    5,893,718      Wisconsin      Wisconsin    5,893,718      Wisconsin  \n",
      "39      576,851        Wyoming        Wyoming      576,851        Wyoming  \n",
      "\n",
      "[40 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b43601",
   "metadata": {},
   "source": [
    "# Break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50684f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize an empty list\n",
    "rows = []\n",
    "\n",
    "# Iterate over all rows in the faculty table\n",
    "for location in starbucks:\n",
    "    \n",
    "    #print(cells)\n",
    "\n",
    "    # Find the name of the course in cell[0]\n",
    "    state_tag = location.find(\"a\")\n",
    "    if state_tag is not None:\n",
    "        state = state_tag.text\n",
    "    else:\n",
    "        None\n",
    "\n",
    "    # Append this data.\n",
    "    rows.append({\n",
    "        \"State\": state\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "data = pd.DataFrame(rows)\n",
    "\n",
    "#data[\"State\"] = data[\"State\"].apply(lambda x: x.replace(\"Starbucks Coffee locations \", \"\").replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "\n",
    "#data[[\"State\", \"Starbucks Coffee Locations\"]] = data[\"State\"].str.rsplit(\" \", 1, expand = True)\n",
    "\n",
    "#data = data[data[\"State\"].isin(states)]\n",
    "\n",
    "#data[\"ST\"] = data[\"State\"].map(state_abbreviations)\n",
    "\n",
    "#data = data[[\"State\", \"ST\", \"Starbucks Coffee Locations\"]]\n",
    "\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code\n",
    "# Initialize an empty list\n",
    "rows = []\n",
    "\n",
    "# Iterate over all rows in the faculty table\n",
    "for location in starbucks:\n",
    "    \n",
    "    #print(cells)\n",
    "\n",
    "    # Find the name of the course in cell[0]\n",
    "    state_tag = location.find(\"a\")\n",
    "    if state_tag is not None:\n",
    "        state = state_tag.text\n",
    "    else:\n",
    "        None\n",
    "\n",
    "    # Append this data.\n",
    "    rows.append({\n",
    "        \"State\": state\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "data = pd.DataFrame(rows)\n",
    "\n",
    "data[\"State\"] = data[\"State\"].apply(lambda x: x.replace(\"Starbucks Coffee locations \", \"\").replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "\n",
    "data[[\"State\", \"Starbucks Coffee Locations\"]] = data[\"State\"].str.rsplit(\" \", 1, expand = True)\n",
    "\n",
    "data = data[data[\"State\"].isin(states)]\n",
    "\n",
    "data[\"ST\"] = data[\"State\"].map(state_abbreviations)\n",
    "\n",
    "data = data[[\"State\", \"ST\", \"Starbucks Coffee Locations\"]]\n",
    "\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
